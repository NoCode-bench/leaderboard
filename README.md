
<div align="center">
  <h1 align="center">NoCode-bench: A Benchmark for Evaluating Natural
Language-Driven Feature Addition</h1>
</div>

<div align="center">
    <a href="https://github.com/ZJU-CTAG/NoCode-bench">
        <img src="https://img.shields.io/badge/GitHub-000?logo=github&logoColor=FFE165&style=for-the-badge" alt="致谢">
    </a>
    <a href="https://huggingface.co/NoCode-bench">
        <img src="https://img.shields.io/badge/Datasets-000?logo=huggingface&logoColor=FFE165&style=for-the-badge" alt="查看文档">
    </a>
    <a href="https://arxiv.org/pdf/2507.18130">
        <img src="https://img.shields.io/badge/Paper-000?logoColor=FFE165&logo=arxiv&style=for-the-badge" alt="Arxiv论文">
    </a>
    <a href="">
        <img src="https://img.shields.io/badge/Leaderboard-000?logoColor=FFE165&logo=googledocs&style=for-the-badge" alt="评估基准分数">
    </a>
    <hr>
</div>

## How to submit?

If you are interested in submitting your system or model to any of our leaderboards (NoCode-bench [Verified, Full]), please follow the instructions posted at [ZJU-CTAG/nocode-bench-experiments](https://github.com/ZJU-CTAG/nocode-bench-experiments).